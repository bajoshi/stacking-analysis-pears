{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack fitting Jupyter module.\n"
     ]
    }
   ],
   "source": [
    "print(\"Stack fitting Jupyter module.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to include latex math: $\\mathrm{F_\\lambda\\ [erg\\, s^{-1}\\, cm^{-2}\\, \\AA]} \n",
    "= \\frac{L \\times L_\\odot}{4 \\pi d_l^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlibrc: /Users/bhavinjoshi/miniconda3/envs/astroconda/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import time\n",
    "\n",
    "# Check that it imported the correct matplotlibrc\n",
    "import matplotlib\n",
    "print(\"Using matplotlibrc:\", matplotlib.matplotlib_fname())\n",
    "\n",
    "# To get figures to show up as a pop up\n",
    "%matplotlib widget\n",
    "\n",
    "# To get figures to show up within the notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "home = os.getenv('HOME')\n",
    "figs_dir = home + \"/Documents/pears_figs_data/\"\n",
    "stacking_analysis_dir = home + \"/Documents/GitHub/stacking-analysis-pears/\"\n",
    "stacking_figures_dir = home + \"/Documents/stacking_figures/\"\n",
    "massive_galaxies_dir = home + \"/Documents/GitHub/massive-galaxies/\"\n",
    "pears_spectra_dir = home + \"/Documents/pears_figs_data/data_spectra_only/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define redshift range \n",
    "z_low = 0.16\n",
    "z_high = 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in saved stack\n",
    "stack = np.genfromtxt(stacking_analysis_dir + 'massive_stack_pears_' + str(z_low) + 'z' + str(z_high) + '.txt', \\\n",
    "                      dtype=None, names=['lam', 'flam', 'flam_err'], encoding='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total models: 37761\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "models_llam = np.load(figs_dir + 'model_comp_spec_llam_withlines_chabrier.npy', mmap_mode='r')\n",
    "models_grid = np.load(figs_dir + 'model_lam_grid_withlines_chabrier.npy', mmap_mode='r')\n",
    "\n",
    "total_models = len(models_llam)\n",
    "print(\"Total models:\", total_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSF convolution done.\n"
     ]
    }
   ],
   "source": [
    "# Loop over all models and modify them\n",
    "# ------------ NO COVARIANCE MATRIX FOR THE MOMENT ------------- # \n",
    "# First do the convolution with the LSF\n",
    "\n",
    "# LSF defined as a Gaussian for now\n",
    "lsf_sigma = 20.0  # this is in Angstroms?\n",
    "\n",
    "models_lsfconv = np.zeros(models_llam.shape)\n",
    "\n",
    "# Seems like it takes the same amount of time for the explicit\n",
    "# for loop and the vectorized computation at least for the two\n",
    "# machines this has been tested on. Probably due to lack of enough \n",
    "# RAM. Vectorized should be faster on a machine with more memory.\n",
    "# I'm sticking with the vectorized version for now.\n",
    "# \n",
    "# ---- Use the code block below to check\n",
    "\"\"\"\n",
    "t1 = time.time()\n",
    "\n",
    "for i in range(total_models):\n",
    "    models_lsfconv[i] = scipy.ndimage.gaussian_filter1d(input=models_llam[i], sigma=lsf_sigma)\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time taken for for loop:\", \"{:.2f}\".format(t2 - t1), \"seconds.\")\n",
    "    \n",
    "# Without for loop over all models\n",
    "models_lsfconv_nofor = scipy.ndimage.gaussian_filter1d(input=models_llam, sigma=lsf_sigma, axis=1)\n",
    "\n",
    "t3 = time.time()\n",
    "print(\"Time taken for vectorized computation:\", \"{:.2f}\".format(t3 - t2), \"seconds.\")\n",
    "\n",
    "print(\"Arrays equal:\", np.array_equal(models_lsfconv_nofor, models_lsfconv))\n",
    "\n",
    "t4 = time.time()\n",
    "print(\"Time taken for array comparison:\", \"{:.2f}\".format(t4 - t3), \"seconds.\")\n",
    "\"\"\"\n",
    "\n",
    "models_lsfconv = scipy.ndimage.gaussian_filter1d(input=models_llam, sigma=lsf_sigma, axis=1)\n",
    "\n",
    "print(\"LSF convolution done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37761, 13228)\n"
     ]
    }
   ],
   "source": [
    "print(models_lsfconv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4c3a115e7ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                    (models_grid < resampling_grid[j+1]))[0]\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmodels_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_lsfconv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m### Last element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now do the resampling\n",
    "# Define array to save modified models\n",
    "resampling_grid = stack['lam']\n",
    "models_mod = np.zeros((total_models, len(resampling_grid)))\n",
    "\n",
    "### Zeroth element\n",
    "lam_step = resampling_grid[1] - resampling_grid[0]\n",
    "idx = np.where((models_grid >= resampling_grid[0] - lam_step) & \\\n",
    "               (models_grid < resampling_grid[0] + lam_step))[0]\n",
    "models_mod[:, 0] = np.mean(models_lsfconv[:, idx], axis=1)\n",
    "\n",
    "### all elements in between\n",
    "for j in range(1, len(resampling_grid) - 1):\n",
    "    # sys.stdout.write('\\r' + str(j))\n",
    "    # The above line will print 'j' at each iteration but not on a new line\n",
    "    # Useful for seeing how fast the code is going on a slower machine\n",
    "    # \\r stands for carriage return... effectively flushes whatever is already printed\n",
    "    print(j, end='\\r')  # Accomplishes the same thing as above without needing the sys package\n",
    "    idx = np.where((models_grid >= resampling_grid[j-1]) & \\\n",
    "                   (models_grid < resampling_grid[j+1]))[0]\n",
    "    models_mod[:, j] = np.mean(models_lsfconv[:, idx], axis=1)\n",
    "\n",
    "### Last element\n",
    "lam_step = resampling_grid[-1] - resampling_grid[-2]\n",
    "idx = np.where((models_grid >= resampling_grid[-1] - lam_step) & \\\n",
    "               (models_grid < resampling_grid[-1] + lam_step))[0]\n",
    "models_mod[:, -1] = np.mean(models_lsfconv[:, idx], axis=1)\n",
    "\n",
    "print(\"Resampling done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_mod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all models fit a polynomial and divide continuum\n",
    "models_divcont = np.zeros(models_mod.shape)\n",
    "\n",
    "for k in range(total_models):\n",
    "    np_fit = np.polyfit(resampling_grid, models_mod[k], deg=3)\n",
    "    np_polynomial = np.poly1d(np_fit)\n",
    "    \n",
    "    models_divcont[k] = models_mod[k] / np_polynomial(resampling_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute chi2 for each model\n",
    "chi2 = (models_divcont - stack['flam'])**2 / stack['flam_err']**2\n",
    "chi2 = np.nansum(chi2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best fit here gives the starting point for the MCMC sampling\n",
    "best_fit_idx = np.argmin(chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check by plotting best fit model\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(resampling_grid, stack['flam'], '.-', color='mediumblue', linewidth=1.5, \\\n",
    "        markeredgecolor='mediumblue', markersize=1.0, zorder=5)\n",
    "ax.fill_between(resampling_grid, stack['flam'] - stack['flam_err'], stack['flam'] + stack['flam_err'], \\\n",
    "                color='gray', alpha=0.5, zorder=5)\n",
    "\n",
    "ax.axhline(y=1.0, ls='--', color='k')\n",
    "\n",
    "# Now plot best fitting model\n",
    "ax.plot(resampling_grid, models_divcont[best_fit_idx], color='tab:red', linewidth=1.5, \\\n",
    "        markeredgecolor='mediumblue', markersize=1.0, zorder=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Starting the MCMC part ------------------------ #\n",
    "def get_model(model_params, ):\n",
    "    \n",
    "    return model_flam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
