{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack fitting Jupyter module.\n"
     ]
    }
   ],
   "source": [
    "print(\"Stack fitting Jupyter module.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to include latex math: $\\mathrm{F_\\lambda\\ [erg\\, s^{-1}\\, cm^{-2}\\, \\AA]} \n",
    "= \\frac{L \\times L_\\odot}{4 \\pi d_l^2}$\n",
    "\n",
    "Note: \\AA (outside math mode) will not work or $\\AA$ (inside math mode) will not work. Check out: https://github.com/ipython/ipython/issues/5533\n",
    "\n",
    "Therefore, there are these workaround symbols: $\\mathring A$ $\\unicode[serif]{xC5}$ $\\unicode{x212B}$ $\\mathrm{\\mathring A}$. I like $\\mathrm{\\mathring A}$ best so I will use that for the rest of this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlibrc: /Users/baj/miniconda3/envs/astroconda37/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import interpolate\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import time\n",
    "\n",
    "# Check that it imported the correct matplotlibrc\n",
    "import matplotlib\n",
    "print(\"Using matplotlibrc:\", matplotlib.matplotlib_fname())\n",
    "\n",
    "# To get figures to show up as a pop up\n",
    "%matplotlib widget\n",
    "\n",
    "# To get figures to show up within the notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "home = os.getenv('HOME')\n",
    "figs_dir = home + \"/Documents/pears_figs_data/\"\n",
    "stacking_analysis_dir = home + \"/Documents/GitHub/stacking-analysis-pears/\"\n",
    "stacking_figures_dir = home + \"/Documents/stacking_figures/\"\n",
    "massive_galaxies_dir = home + \"/Documents/GitHub/massive-galaxies/\"\n",
    "pears_spectra_dir = home + \"/Documents/pears_figs_data/data_spectra_only/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define redshift range \n",
    "z_low = 0.16\n",
    "z_high = 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in saved stack\n",
    "stack = np.genfromtxt(stacking_analysis_dir + 'massive_stack_pears_' + str(z_low) + 'z' + str(z_high) + '.txt', \\\n",
    "                      dtype=None, names=['lam', 'flam', 'flam_err'], encoding='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total models: 37761\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "models_llam = np.load(figs_dir + 'model_comp_spec_llam_withlines_chabrier.npy', mmap_mode='r')\n",
    "models_grid = np.load(figs_dir + 'model_lam_grid_withlines_chabrier.npy', mmap_mode='r')\n",
    "\n",
    "total_models = len(models_llam)\n",
    "print(\"Total models:\", total_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some notes on the choice of the lsf_sigma below. (This will be a hand-wavy argument)\n",
    "\n",
    "1. It has to be in Angstroms. This is because we are convolving/filtering the spectrum which is spaced in the units of wavelength, i.e., angstroms.\n",
    "2. For an object at $z\\sim0.6$ (approx median of our redshift distribution) \n",
    "3. PEARS data is taken by ACS/G800L which has a spectral resolution of $R=\\frac{\\delta\\lambda}{\\lambda}\\sim100$ at 8000$\\mathrm{\\mathring A}$. See: https://hst-docs.stsci.edu/acsihb/chapter-6-polarimetry-coronagraphy-prism-and-grism-spectroscopy/6-3-grism-and-prism-spectroscopy. This resolution is only achieved for point sources. For extended objects this resolution is even worse. \n",
    "4. So, say at the approximate middle of our stack's wavelength coverage (say 3600$\\mathrm{\\mathring A}$ to 6200$\\mathrm{\\mathring A}$), i.e., at 4900$\\mathrm{\\mathring A}$, *if* we could get this best spectral resolution then the spectral coverage per element or pixel would be: $\\frac{4900}{R}=49\\mathrm{\\mathring A}$.\n",
    "5. However, we do not get this best spectral resolution since the galaxies we are considering are not point sources. Therefore, I'll assume for the sake of this order-of-magnitude calculation that we get $R\\sim80$ on average for the galaxies considered below.\n",
    "6. Now, at 4900A and assuming an $R\\sim80$ we get a coverage of $\\frac{4900}{80}=61.25\\mathrm{\\mathring A}$ per spectral element.\n",
    "7. Finally, assuming that galaxies have a 1$\\sigma$ width along the dispersion direction of 2 pixels, I get the LSF sigma should be $61.25\\times2 = 122.5\\mathrm{\\mathring A}$. This will be my LSF sigma below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSF convolution done.\n"
     ]
    }
   ],
   "source": [
    "# Loop over all models and modify them\n",
    "# ------------ NO COVARIANCE MATRIX FOR THE MOMENT ------------- # \n",
    "# First do the convolution with the LSF\n",
    "\n",
    "# LSF defined as a Gaussian for now\n",
    "lsf_sigma = 122.5  # this is in Angstroms\n",
    "\n",
    "models_lsfconv = np.zeros(models_llam.shape)\n",
    "\n",
    "# Seems like it takes the same amount of time for the explicit\n",
    "# for loop and the vectorized computation at least for the two\n",
    "# machines this has been tested on. Probably due to lack of enough \n",
    "# RAM. Vectorized should be faster on a machine with more memory.\n",
    "# I'm sticking with the vectorized version for now.\n",
    "# \n",
    "# ---- Use the code block below to check\n",
    "\"\"\"\n",
    "t1 = time.time()\n",
    "\n",
    "for i in range(total_models):\n",
    "    models_lsfconv[i] = scipy.ndimage.gaussian_filter1d(input=models_llam[i], sigma=lsf_sigma)\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Time taken for for loop:\", \"{:.2f}\".format(t2 - t1), \"seconds.\")\n",
    "    \n",
    "# Without for loop over all models\n",
    "models_lsfconv_nofor = scipy.ndimage.gaussian_filter1d(input=models_llam, sigma=lsf_sigma, axis=1)\n",
    "\n",
    "t3 = time.time()\n",
    "print(\"Time taken for vectorized computation:\", \"{:.2f}\".format(t3 - t2), \"seconds.\")\n",
    "\n",
    "print(\"Arrays equal:\", np.array_equal(models_lsfconv_nofor, models_lsfconv))\n",
    "\n",
    "t4 = time.time()\n",
    "print(\"Time taken for array comparison:\", \"{:.2f}\".format(t4 - t3), \"seconds.\")\n",
    "\"\"\"\n",
    "\n",
    "models_lsfconv = scipy.ndimage.gaussian_filter1d(input=models_llam, sigma=lsf_sigma, axis=1)\n",
    "\n",
    "print(\"LSF convolution done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37761, 13228)\n"
     ]
    }
   ],
   "source": [
    "print(models_lsfconv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling done.\n"
     ]
    }
   ],
   "source": [
    "# Now do the resampling\n",
    "# Define array to save modified models\n",
    "resampling_grid = stack['lam']\n",
    "\n",
    "models_mod = np.zeros((total_models, len(resampling_grid)))\n",
    "\n",
    "### Zeroth element\n",
    "lam_step = resampling_grid[1] - resampling_grid[0]\n",
    "idx = np.where((models_grid >= resampling_grid[0] - lam_step) & \\\n",
    "               (models_grid < resampling_grid[0] + lam_step))[0]\n",
    "models_mod[:, 0] = np.mean(models_lsfconv[:, idx], axis=1)\n",
    "\n",
    "### all elements in between\n",
    "for j in range(1, len(resampling_grid) - 1):\n",
    "    # sys.stdout.write('\\r' + str(j))\n",
    "    # The above line will print 'j' at each iteration but not on a new line\n",
    "    # Useful for seeing how fast the code is going on a slower machine\n",
    "    # \\r stands for carriage return... effectively flushes whatever is already printed\n",
    "    # print(j, end='\\r')  # Accomplishes the same thing as above without needing the sys package\n",
    "    idx = np.where((models_grid >= resampling_grid[j-1]) & \\\n",
    "                   (models_grid < resampling_grid[j+1]))[0]\n",
    "    models_mod[:, j] = np.mean(models_lsfconv[:, idx], axis=1)\n",
    "\n",
    "### Last element\n",
    "lam_step = resampling_grid[-1] - resampling_grid[-2]\n",
    "idx = np.where((models_grid >= resampling_grid[-1] - lam_step) & \\\n",
    "               (models_grid < resampling_grid[-1] + lam_step))[0]\n",
    "models_mod[:, -1] = np.mean(models_lsfconv[:, idx], axis=1)\n",
    "\n",
    "print(\"Resampling done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37761, 184)\n"
     ]
    }
   ],
   "source": [
    "print(models_mod.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all resampled models fit a polynomial and divide continuum. Rebin to a large delta-lambda first.\n",
    "models_divcont = np.zeros(models_mod.shape)\n",
    "\n",
    "# Rebin data \n",
    "rebin_step = 250.0\n",
    "rebin_start = int(resampling_grid[0] / rebin_step) * rebin_step\n",
    "rebin_end = int(resampling_grid[-1] / rebin_step) * rebin_step\n",
    "rebin_grid = np.arange(rebin_start, rebin_end + rebin_step, rebin_step)\n",
    "\n",
    "for k in range(total_models):\n",
    "    \n",
    "    model_rebinned = interpolate.griddata(points=resampling_grid, values=models_mod[k], \\\n",
    "    xi=rebin_grid, method='cubic')    \n",
    "    \n",
    "    np_fit = np.polyfit(rebin_grid, model_rebinned, deg=10)\n",
    "    np_polynomial = np.poly1d(np_fit)\n",
    "    \n",
    "    models_divcont[k] = models_mod[k] / np_polynomial(resampling_grid)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Plot to check\n",
    "    print(\"Working on model index:\", k)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(resampling_grid, models_mod[k], label='Resampled model')\n",
    "    ax.plot(rebin_grid, model_rebinned, label='Rebinned model')\n",
    "    ax.plot(resampling_grid, np_polynomial(resampling_grid), label='Polynomial fit')\n",
    "    \n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if k > kinit + 10: break\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute chi2 for each model\n",
    "chi2 = (models_divcont - stack['flam'])**2 / stack['flam_err']**2\n",
    "chi2 = np.nansum(chi2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best fit here gives the starting point for the MCMC sampling\n",
    "best_fit_idx = np.argmin(chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210dffb5db2743138618812933553a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check by plotting best fit model\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel(r'$\\mathrm{Wavelength\\ [\\AA]}$', fontsize=15)\n",
    "ax.set_ylabel(r'$\\mathrm{L_{\\lambda}\\ (divided\\ by\\ continuum)}$', fontsize=15)\n",
    "\n",
    "# Plot stack and errors\n",
    "ax.plot(resampling_grid, stack['flam'], '.-', color='mediumblue', linewidth=1.5, \\\n",
    "        markeredgecolor='mediumblue', markersize=1.0, zorder=5)\n",
    "ax.fill_between(resampling_grid, stack['flam'] - stack['flam_err'], stack['flam'] + stack['flam_err'], \\\n",
    "                color='gray', alpha=0.5, zorder=5)\n",
    "\n",
    "# Now plot best fitting model\n",
    "ax.plot(resampling_grid, models_divcont[best_fit_idx], color='tab:red', linewidth=1.5, zorder=5)\n",
    "\n",
    "# Horizontal line at 1.0\n",
    "ax.axhline(y=1.0, ls='--', color='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Starting the MCMC part ------------------------ #\n",
    "def get_model(model_params, ):\n",
    "    \n",
    "    return model_flam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
